# Neural Machine Translation with RNN variants.

## Introduction
Encoder-Decoder architecture for neural machine translation `BN->EN`.
* Both LSTM and GRU can be used as Encoder or Decoder.
* Scratch implementation of vocab `language.py` and trainer `trainer.py` class.
* Implementation of [Bahdanau attention decoder](https://arxiv.org/pdf/1409.0473.pdf).

## Setup
Install the following if not installed.
* python 3.x
* torch cuda version
* scarceblue
* configparser
`language.py` and trainer `trainer.py` class.
